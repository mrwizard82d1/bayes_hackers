{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 01\n",
    "\n",
    "## Introduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noinspection PyUnresolvedReferences\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "# noinspection PyUnresolvedReferences\n",
    "import scipy.stats as stats\n",
    "# noinspection PyUnresolvedReferences\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the `figsize` utility function\n",
    "from IPython.core.pylabtools import figsize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import fractions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A farmer or a librarian?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 300 dots per inch for saved figures and inline plots\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['figure.dpi'] = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prior = np.array([fractions.Fraction(1, 21), fractions.Fraction(20, 21)])\n",
    "likelihood = np.array([fractions.Fraction(95, 100), fractions.Fraction(5, 10)])\n",
    "products = prior * likelihood\n",
    "posterior = products / sum(products)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = ['#348abd', '#a60628']\n",
    "plt.bar([0, 0.7], prior, alpha=0.7, width=0.25, color = colors[0],\n",
    "        label='Prior distribution', lw='3', edgecolor=colors[0])\n",
    "plt.bar([0 + 0.25, 0.7 + 0.25], posterior, alpha=0.7, width=0.25,\n",
    "        color=colors[1], label='Posterior distribution',\n",
    "        lw='3', edgecolor=colors[1])\n",
    "plt.xticks([0.20, 0.95], ['Librarian', 'Farmer'])\n",
    "plt.title(\"Prior and posterior probabilities of Steve's occupation.\")\n",
    "plt.ylabel('Probability')\n",
    "plt.legend(loc='upper left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A probability distribution is a function of a random variable, often\n",
    "called _Z_, that maps _Z_ to a value such that the sum over all values of\n",
    "_Z_ (either continuous or discrete) is one. That is, a probability\n",
    "distribution is a function whose sum over all range values for each member\n",
    "of the domain is exactly one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Poisson distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A Poisson distribution is a discrete distribution (each member of the domain\n",
    "is \"distinct\" or \"seperated\" from other members of the domain). The domain\n",
    "of the Poisson distribution is the set of non-negative integers (infinite,\n",
    "but countably infinite). The shape is controlled by a single (shape?)\n",
    "parameter, _lambda_. Higher values of _lambda_ result in a higher probability\n",
    "mass for larger elements of the domain.\n",
    "\n",
    "The mean, first moment, or expectation of a Poisson distribution with\n",
    "parameter, _lambda_, is $\\lambda$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot on a 12.5\" x 4\" canvas\n",
    "plt.figure(figsize=(12.5, 4))\n",
    "# Using two colors\n",
    "colors = ['#348abd', '#a60628']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot two different Poisson distributions (probability mass functions)\n",
    "a = np.arange(16)  # 16 x-values\n",
    "poi = stats.poisson  # save a couple of keystrokes\n",
    "# Note the trailing underscore because `lambda` is a keyword\n",
    "lambda_ = [1.5, 4.25]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the probability \"mass\" of the Poisson distribution at each _a_\n",
    "plt.bar(a, poi.pmf(a, lambda_[0]), color=colors[0],\n",
    "        label=f'$\\lambda = {lambda_[0]:.1f}$', alpha=0.60, edgecolor=colors[0], lw='3')\n",
    "plt.bar(a, poi.pmf(a, lambda_[1]), color=colors[1],\n",
    "        label=f'$\\lambda = {lambda_[1]:.1f}$', alpha=0.60, edgecolor=colors[1], lw='3')\n",
    "plt.xticks(a + 0.4, a)\n",
    "plt.legend()\n",
    "plt.ylabel('Probability of $k$')\n",
    "plt.xlabel('$k$')\n",
    "plt.title('Probability mass function of a Poisson random variable but'\n",
    "          ' differing $\\lambda$ values.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exponential distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An exponential distribution is a continuous distribution (members of the domain\n",
    "are continuous). The domain of the exponential distribution is the set of\n",
    "real numbers. The shape is controlled by a single (shape?) parameter, _lambda_.\n",
    "Higher values of _lambda_ result in a higher probability mass for larger members\n",
    "of the domain.\n",
    "\n",
    "The mean, first moment, or expectation of an exponential distribution with\n",
    "parameter, _lambda_, is $1 / \\lambda$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.linspace(0, 4, 100)  # Sample real numbers linearly\n",
    "expo = stats.expon\n",
    "lambda_ = [0.5, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for l, c in zip(lambda_, colors):\n",
    "    plt.plot(a, expo.pdf(a, scale=1 / l), lw=3, color=c,\n",
    "                         label=f'$\\lambda$ = {l:.1f}')\n",
    "    plt.fill_between(a, expo.pdf(a, scale=1 / l), color=c, alpha=0.33)\n",
    "plt.legend()\n",
    "plt.ylabel('Probability density function at $z$')\n",
    "plt.xlabel('$z$')\n",
    "plt.ylim(0, 1.2)\n",
    "plt.title('Probability density function of an exponential random variable,'\n",
    "          ' differing $\\lambda$ values')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayesian inference using computers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You are given a series of daily text message counts from a user of your\n",
    "system. You are curious if the user's text messaging habits have changed\n",
    "over time, either gradually or suddenly. How can you model this?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot the text message counts over time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot on a 12.5\" x 3.5\" \"canvas\"\n",
    "plt.figure(figsize=(12.5, 3.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in the data (single column text file, I believe)\n",
    "count_data = np.loadtxt('data/txtdata.csv')\n",
    "n_count_data = len(count_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot a bar chart: text message counts over time\n",
    "plt.bar(np.arange(n_count_data), count_data, color='#348abd')\n",
    "plt.xlabel('Time (days)')\n",
    "plt.ylabel('Text messages received')\n",
    "plt.title(\"Did the user's texting habits change over time?\")\n",
    "plt.xlim(0, n_count_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modeling the counts over time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The author suggests modeling the counts using a Poisson distribution; that is,\n",
    "$$\n",
    "C_{i} \\sim \\mathrm{Poisson}(\\lambda)\n",
    "$$\n",
    "\n",
    "However, $\\lambda$, is a parameter whose value is **unknown**; consequently, we use Bayesian inference to infer a distribution of values for this parameter.\n",
    "\n",
    "The author further posits that $\\lambda$ actually changes (discontinuously) over time. That is, $\\lambda$ is drawn from a _switchover_ at time, $\\tau$.\n",
    "\n",
    "$$\n",
    "\\lambda = \\left\\{\n",
    "    \\begin{array}\\\\\n",
    "        \\lambda_{1} \\mbox{ if } \\mathrm{t} < \\tau \\\\\n",
    "        \\lambda_{2} \\mbox{ if } \\mathrm{t} \\geq \\tau\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "In order to infer the values $\\lambda_{1}$ and $\\lambda_{2}$, we must assign prior probabilities to these values. Because the $\\lambda$ parameter for the Poisson distribution accepts any **positive** number, we need a distribution that generates positive numbers. The exponential distribution provides a continuous distribution for positive values so the author suggests using this distribution as follows:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "    \\lambda_{1} \\sim \\mathrm{Exp}(\\alpha) \\\\\n",
    "    \\lambda_{2} \\sim \\mathrm{Exp}(\\alpha)\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where \\alpha is a _hyperparameter_; that is, a parameter that influences other **parameters**.\n",
    "\n",
    "The author argues that setting $\\alpha$ to the inverse of the sample average of the count data like\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\mathrm{N}} \\sum_{i = 0}^{\\mathrm{N}} \\mathrm{C}_{i} \\approx \\mathbb{E} [ \\lambda\\mid\\alpha ] = \\frac{1}{\\alpha}\n",
    "$$\n",
    "\n",
    "The author does not detail his reasoning for this choice; however, the following explanation seems reasonable to me.\n",
    "\n",
    "The counts are distributed as a Poisson distribution with parameter $\\lambda$. The expectation of a Poisson distribution with parameter $\\lambda$ is also $\\lambda$. The sample mean of the counts is given by the summation expression in the previous section, and we want the sample mean to be the inverse of $\\alpha$ but $\\frac{1}{\\alpha}$ is also the expectation of the parameter, $\\lambda \\mid \\alpha$, for the exponential distribution.\n",
    "\n",
    "The author states that this choice of hyperparameter is \"not very opinionated in our prior\"; that is, the prior minimizes the influence of the hyperparameter.\n",
    "\n",
    "Finally, the author posits using a uniform distribution for $\\tau$, the time at which the $\\lambda$ parameter of the Poisson distribution changes. That is,\n",
    "\n",
    "$$\n",
    "\\tau \\sim \\mathrm{DiscreteUniform}(0, 70)\n",
    "$$\n",
    "\n",
    "He argues that this choice is reasonable because of the noisiness of the data.\n",
    "\n",
    "This distribution implies that\n",
    "\n",
    "$$\n",
    "\\mathcal{P}(\\tau = \\mathcal{k}) = \\frac{1}{70}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducing our first hammer: PyMC3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha = 1.0 / count_data.mean()  ## `count_data` holds our text counts\n",
    "with pm.Model() as model:\n",
    "    # One must create all the stochastic variables in the context of a model\n",
    "    lambda_1 = pm.Exponential('lambda_1', alpha)\n",
    "    lambda_2 = pm.Exponential('lambda_2', alpha)\n",
    "    tau = pm.DiscreteUniform('tau', lower=0, upper=n_count_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with model:\n",
    "    # We also define a deterministic `lambda_` inside a model\n",
    "    idx = np.arange(n_count_data)\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We add our observed data:\n",
    "with model:\n",
    "    obs = pm.Poisson('obs', lambda_, observed=count_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finally, within a model, sample the data\n",
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(10000, tune=5000, step=step, return_inferencedata=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lambda_1_samples = trace['lambda_1']\n",
    "lambda_2_samples = trace['lambda_2']\n",
    "tau_samples = trace['tau']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the posterior samples\n",
    "figsize(14.5, 10)\n",
    "\n",
    "ax = plt.subplot(311)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(lambda_1_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label='posterior of $lambda_1$', color='#a60628', density=True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(r\"\"\"Posterior distributions of the parameters $\\lambda_1,\\;\\lambda_2,\\;\\tau$\"\"\")\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel('$\\lambda_1$ value')\n",
    "\n",
    "ax = plt.subplot(312)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(lambda_2_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label='posterior of $lambda_2$', color='#7a68a6', density=True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel('$\\lambda_2$ value')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "ax = plt.subplot(313)\n",
    "w = 1 / tau_samples.shape[0] * np.ones_like(tau_samples)\n",
    "plt.hist(tau_samples, bins=n_count_data, alpha=1, label='posterior of $\\tau$',\n",
    "         color='#467821', weights=w, rwidth=2.)\n",
    "plt.xticks(np.arange(n_count_data))\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([0, 0.75])\n",
    "plt.xlim([35, len(count_data) - 20])\n",
    "plt.xlabel(r'$\\tau$ (in days)')\n",
    "plt.ylabel('Probability')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha = 1.0 / count_data.mean()  ## `count_data` holds our text counts\n",
    "with pm.Model() as model:\n",
    "    # One must create all the stochastic variables in the context of a model\n",
    "    lambda_1 = pm.Exponential('lambda_1', alpha)\n",
    "    lambda_2 = pm.Exponential('lambda_2', alpha)\n",
    "    tau = pm.DiscreteUniform('tau', lower=0, upper=n_count_data)\n",
    "\n",
    "    # We also define a deterministic `lambda_` inside a model\n",
    "    idx = np.arange(n_count_data)\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)\n",
    "\n",
    "    # Add the observed data\n",
    "    obs = pm.Poisson('obs', lambda_, observed=count_data)\n",
    "\n",
    "    # And sample the data\n",
    "    step = pm.Metropolis()\n",
    "    idata = pm.sample(10000, tune=5000, step=step, return_inferencedata=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(16, 12), squeeze=False)\n",
    "az.plot_posterior(idata, ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpretation\n",
    "\n",
    "What have we gained:\n",
    "\n",
    "- Uncertainty in our estimates\n",
    "- Plausible values for parameters\n",
    "- Posterior distributions of the two lambdas are clearly different\n",
    "- Distribution of tau is narrow; that is, a small range for switch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What good are samples from the posterior, anyway?\n",
    "\n",
    "We'll use posterior samples to answer the following question: What is the expected number of texts at day, `t` $0 \\leq t \\leq 70$.\n",
    "\n",
    "This question is equivalent to: What is the expected value of $\\lambda$ at time $t$?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following code, let $i$ index samples from the posterior distributions. Given a day, $t$, we average over all possible $\\lambda_i$ for that day, $t$, using $\\lambda_i = \\lambda_{1,i}$ if $\\tau < \\tau_i$ (that is, if the change has not yet occurred), else we use $\\lambda_i = \\lambda_{2,i}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figsize(12.5, 5)\n",
    "\n",
    "# tau_samples, lambda_1_samples, and lambda_2_samples each contain N samples\n",
    "# from the corresponding posterior distribution.\n",
    "\n",
    "N = tau_samples.shape[0]\n",
    "expected_texts_per_day = np.zeros(n_count_data)\n",
    "\n",
    "for day in range(n_count_data):\n",
    "    # `ix` is a boolean index of all `tau_samples` corresponding to the\n",
    "    # switch point occurring prior to the value of `day`.\n",
    "    ix = day < tau_samples\n",
    "\n",
    "    # Each posterior sample corresponds to a value for `tau`.\n",
    "    #\n",
    "    # For each day, that value of `tau` indicates whether we are \"before\"\n",
    "    # (that is, in the `lambda_1` \"regime\") or \"after\" (that is, in the\n",
    "    # \"lambda_2\" \"regime\") the switch point.\n",
    "    #\n",
    "    # By taking the posterior sample of `lambda_1` and `lambda_2` accordingly,\n",
    "    # we can average over all samples to get an expected value for `lambda`\n",
    "    # on that day.\n",
    "    #\n",
    "    # As explained, the \"message count\" random variable is Poisson-\n",
    "    # distributed, and therefore, `lambda`, the Poisson parameter, is the\n",
    "    # expected value of \"message count.\"\n",
    "    expected_texts_per_day[day] = (lambda_1_samples[ix].sum() +\n",
    "                                   lambda_2_samples[~ix].sum()) / N\n",
    "\n",
    "plt.plot(range(n_count_data), expected_texts_per_day, lw=4,\n",
    "         color='#e24a33',\n",
    "         label='Expected number of text messages received')\n",
    "plt.xlim(0, n_count_data)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Number of text messages')\n",
    "plt.title('Number of text messages received versus expected number received')\n",
    "plt.ylim(0, 60)\n",
    "plt.bar(np.arange(len(count_data)), count_data, color='#348abd',\n",
    "        alpha=0.65, label='Observed text message per day')\n",
    "plt.legend(loc='upper left')\n",
    "print(expected_texts_per_day)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The author, in section 1.4.1, encourages the reader to try a different model with two different $\\alpha$ values. Here's my attempt.\n",
    "\n",
    "I'm going to split the original $\\alpha$, set to the inverse of the mean of the counts, to be a \"mixture\" of two different means. The first mean is the average of the `count_data` over the first 50 days and the second mean is the average of the `count_data` over days 30 and beyond. This includes where I believe the change occurs, but instead of picking a specific day, overlaps the two averages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha_1 = 1.0 / count_data[:50].mean()  ## inverse of the average of the first 50 days of `count_data`\n",
    "alpha_2 = 1.0 / count_data[30:].mean()  ## inverse of the average of the days 30 to the end of `count_data`\n",
    "with pm.Model() as model:\n",
    "    # One must create all the stochastic variables in the context of a model\n",
    "    lambda_1 = pm.Exponential('lambda_1', alpha_1)\n",
    "    lambda_2 = pm.Exponential('lambda_2', alpha_2)\n",
    "    tau = pm.DiscreteUniform('tau', lower=0, upper=n_count_data)\n",
    "\n",
    "    # We also define a deterministic `lambda_` inside a model\n",
    "    idx = np.arange(n_count_data)\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)\n",
    "\n",
    "    # Add the observed data\n",
    "    obs = pm.Poisson('obs', lambda_, observed=count_data)\n",
    "\n",
    "    # And sample the data\n",
    "    step = pm.Metropolis()\n",
    "    idata = pm.sample(10000, tune=5000, step=step, return_inferencedata=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Surprisingly) Nice that it sampled without warnings or errors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(16, 12), squeeze=False)\n",
    "az.plot_posterior(idata, ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I see some differences between the posterior plots; however, I do not know enough to judge if these differences are significant or could simply be the random samples that occurred during these two runs.\n",
    "\n",
    "I wonder what the result is if I pick a \"hard\" but \"incorrect\" switchover date for $\\alpha$. Hmmm. It's pretty easy to try. :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# I will pick the `alpha` change to occur on day 30. I do not believe this day, but I want to see what affect this has on the result.\n",
    "alpha_1 = 1.0 / count_data[:30].mean()  ## inverse of the average of the first 30 days of `count_data`\n",
    "alpha_2 = 1.0 / count_data[30:].mean()  ## inverse of the average of the days 30 to the end of `count_data`\n",
    "with pm.Model() as model:\n",
    "    # One must create all the stochastic variables in the context of a model\n",
    "    lambda_1 = pm.Exponential('lambda_1', alpha_1)\n",
    "    lambda_2 = pm.Exponential('lambda_2', alpha_2)\n",
    "    tau = pm.DiscreteUniform('tau', lower=0, upper=n_count_data)\n",
    "\n",
    "    # We also define a deterministic `lambda_` inside a model\n",
    "    idx = np.arange(n_count_data)\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)\n",
    "\n",
    "    # Add the observed data\n",
    "    obs = pm.Poisson('obs', lambda_, observed=count_data)\n",
    "\n",
    "    # And sample the data\n",
    "    step = pm.Metropolis()\n",
    "    idata = pm.sample(10000, tune=5000, step=step, return_inferencedata=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That behavior is surprising. I expected my hard cut over to make a difference, but it appears to have little effect."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a final experiment, instead of specifying the step, I will use the approach recommended by the PyMC3 documentation and simply sample the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha = 1.0 / count_data.mean()  ## `count_data` holds our text counts\n",
    "with pm.Model() as model:\n",
    "    # One must create all the stochastic variables in the context of a model\n",
    "    lambda_1 = pm.Exponential('lambda_1', alpha)\n",
    "    lambda_2 = pm.Exponential('lambda_2', alpha)\n",
    "    tau = pm.DiscreteUniform('tau', lower=0, upper=n_count_data)\n",
    "\n",
    "    # We also define a deterministic `lambda_` inside a model\n",
    "    idx = np.arange(n_count_data)\n",
    "    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)\n",
    "\n",
    "    # Add the observed data\n",
    "    obs = pm.Poisson('obs', lambda_, observed=count_data)\n",
    "\n",
    "    # And sample the data\n",
    "    step = pm.Metropolis()\n",
    "    idata = pm.sample(return_inferencedata=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(16, 12), squeeze=False)\n",
    "az.plot_posterior(idata, ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interesting.\n",
    "\n",
    "None of the posteriors seem significantly different in terms of the mean or the 94% HDI; however, I originally thought that the $\\tau$ posterior was \"fatter\" when I let the software sample. However, as I considered this hypotheses, I'm less convinced. The software sampling for $\\tau$  seems to cut off at 41.5 on the low side; when I specified the sampling, it appeared to be zero below 41, but the total left-hand tail is perhaps longer (down to 38).\n",
    "\n",
    "I do not know enough about the details to decide if the story I believe is what the picture is actually communicating. Good I have future questions, but bad that I do not have \"an answer.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Appendix\n",
    "\n",
    "### Determining if the two $\\lambda$s are different"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Determining if the posterior distributions of two different variables (parameters) is fairly straightforward.\n",
    "One merely need to computer the fraction of the time that $\\lambda_1$ is less than $\\lambda_2$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "less_than = lambda_1_samples < lambda_2_samples\n",
    "# `sum` counts the number of True values (because Python treats `True` as 1)\n",
    "less_than_fraction = less_than.sum() / len(less_than)\n",
    "less_than_fraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although absolutely true (1.0) is unexpected, the value reported by the book is 29994 / 30000; that is, very close\n",
    "to 1. I can easily see that another simulation might generate exactly one.\n",
    "\n",
    "In fact, the book does not actually calculate the fraction, but uses `mean()` which uses the same \"trick\" described\n",
    "in the book, _Thinking Bayes_, 2nd edition."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "less_than.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also ask more complicated questions such as, \"What is the probability that $\\lambda_1$ - $\\lambda_2$ is\n",
    "greater than 1? 2? 5? 10?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for greater_than_difference in [0.1, 0.2, 0.3, 0.5, 0.8, 1.3, 2.1, 3.4, 5.5, 8.9, 14.4]:\n",
    "    print(f'Probability that abs(lambda_1 - lambda_2) > {greater_than_difference}:'\n",
    "          f' {(abs(lambda_1_samples - lambda_2_samples) > greater_than_difference).mean()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What if we extend the model to *two* switchpoints?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha = 1.0 / count_data.mean()  ## `count_data` holds our text counts\n",
    "with pm.Model() as three_switch_points:\n",
    "    # One must create all the stochastic variables in the context of a model\n",
    "    lambda_1 = pm.Exponential('lambda_1', alpha)\n",
    "    lambda_2 = pm.Exponential('lambda_2', alpha)\n",
    "    lambda_3 = pm.Exponential('lambda_3', alpha)\n",
    "    tau_1 = pm.DiscreteUniform('tau_1', lower=0, upper=n_count_data - 1)\n",
    "    tau_2 = pm.DiscreteUniform('tau_2', lower=tau_1, upper=n_count_data)\n",
    "\n",
    "\n",
    "    # We also define a deterministic `lambda_` inside a model\n",
    "    idx = np.arange(n_count_data)\n",
    "    # The following, commented out expression produces a `Type` error with the message: \"Variables do not support\n",
    "    # boolean operations.\" I believe the explanation of this error is found on the\n",
    "    # [PyMC3 Discourse post](https://github.com/Theano/Theano/issues/1581). Basically, Theano variables are\n",
    "    # symbolic even though they appear to be Python variables.\n",
    "    # lambda_ = pm.math.switch(idx < tau_1, lambda_1,\n",
    "    #                          pm.math.switch(tau_1 <= idx < tau_2, lambda_2, lambda_3))\n",
    "    lambda_ = pm.math.switch(idx <= tau_1, lambda_1,\n",
    "                             pm.math.switch(idx > tau_2, lambda_3, lambda_2))\n",
    "\n",
    "    # Add the observed data\n",
    "    obs = pm.Poisson('obs', lambda_, observed=count_data)\n",
    "\n",
    "    # And sample the data\n",
    "    # The following code results in issues: a `RuntimeWarning` about invalid values and a warning that the\n",
    "    # number of effective samples is smaller than 10% for some parameters. I tried the \"default\" `sample`\n",
    "    # method instead.\n",
    "    step = pm.Metropolis()\n",
    "    idata = pm.sample(10000, tune=5000, step=step, return_inferencedata=True)\n",
    "    # However, the \"default\" `sample` method produces similar warnings.\n",
    "    # idata = pm.sample(return_inferencedata=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 1, figsize=(12, 20), squeeze=False)\n",
    "az.plot_posterior(idata, ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}